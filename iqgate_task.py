# -*- coding: utf-8 -*-
"""iqgate_task.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1O5iY_QDyM5LPRKVQ9fs5QdLQRCd-EsOu
"""

! pip install -q kaggle

from google.colab import files

files.upload()

pip install opendatasets

import opendatasets as od
import pandas

od.download(
	"https://www.kaggle.com/datasets/iarunava/cell-images-for-detecting-malaria?resource=download")

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import os
import seaborn as sns

cell_types=os.listdir('/content/cell-images-for-detecting-malaria/cell_images/cell_images')
print(cell_types)

cells=[]
for item in cell_types:
  all_cells=os.listdir('/content/cell-images-for-detecting-malaria/cell_images/cell_images'+'/'+item)
  for cell in all_cells:
    cells.append((item,str('/content/cell-images-for-detecting-malaria/cell_images/cell_images'+'/'+item)+'/'+cell))
cells

cells_df=pd.DataFrame(data=cells,columns=['cell_type','image'])
cells_df.head()

print('Total number of cells in the dataset:',len(cells_df))
cells_count=cells_df['cell_type'].value_counts()
print(cells_count)

fig=plt.figure(figsize=(25,10))
sns.set_style("white")
plt.title('Total Number of Classes',fontdict={'fontsize':14})
sns.countplot(cells_df['cell_type'],palette='crest')

import keras
keras.__version__
from keras import layers
from keras import models
from keras import optimizers
import tensorflow as tf

model = models.Sequential()
model.add(layers.Conv2D(32, (3, 3), activation='relu',
                        input_shape=(150,150,3)))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(64, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Conv2D(128, (3, 3), activation='relu'))
model.add(layers.MaxPooling2D((2, 2)))
model.add(layers.Flatten())
model.add(layers.Dropout(0.5))
model.add(layers.Dense(512, activation='relu'))
model.add(layers.Dense(4, activation='softmax'))
model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['acc'])

from sklearn.model_selection import train_test_split
train_df, test_df = train_test_split(cells_df, train_size = 0.89, shuffle = True, random_state=2)
print(train_df.shape, test_df.shape)

train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale = 1./255,
    zoom_range = 0.2,
    height_shift_range = 0.2,
    width_shift_range = 0.2,
    horizontal_flip = True,
    validation_split = 0.2
)
test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)

img_rows, img_cols = 224, 224
batch_size = 32
classes = cells_df['cell_type'].nunique()
classes

train_generator = train_datagen.flow_from_dataframe(
    dataframe = train_df,
    x_col = "image",
    y_col = "cell_type",
    target_size = (img_rows, img_cols),
    batch_size = batch_size,
    subset = "training",
    shuffle = True,
    class_mode = "categorical"
)

val_generator = train_datagen.flow_from_dataframe(
    dataframe = train_df,
    x_col = "image",
    y_col = "cell_type",
    target_size = (img_rows, img_cols),
    batch_size = batch_size,
    subset = "validation",
    shuffle = False,
    class_mode = "categorical"
)

test_generator = test_datagen.flow_from_dataframe(
    dataframe = test_df,
    x_col = "image",
    y_col = "cell_type",
    target_size = (img_rows, img_cols),
    batch_size = batch_size,
    shuffle = False,
    class_mode = "categorical"
)

basemodel = tf.keras.applications.ResNet152V2(
    weights = "imagenet",
    input_shape = (img_rows, img_cols, 3),
    include_top = False
)
for layer in basemodel.layers:
    layer.trainable = False
x = basemodel.output
x = tf.keras.layers.GlobalAveragePooling2D()(x)
x = tf.keras.layers.Dense(1024, activation="relu")(x)
x = tf.keras.layers.Dense(1024, activation="relu")(x)
output = tf.keras.layers.Dense(classes, activation="softmax")(x)
model = tf.keras.Model(inputs = basemodel.inputs, outputs = output)
model.summary()

model.compile(
    loss = "categorical_crossentropy",
    optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),
    metrics = ['accuracy']
)

from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, ReduceLROnPlateau
earlystopper1 = EarlyStopping(monitor='loss', patience=10, verbose=1)
# Save the best model during the traning
checkpointer1 = ModelCheckpoint('best_model1.h1'
                                ,monitor='val_acc'
                                ,verbose=1
                                ,save_best_only=True
                                ,save_weights_only=True)

t_model1 = model.fit(
    train_generator,
    epochs = 5,
    validation_data = val_generator,
    validation_steps = 1,
    callbacks=[earlystopper1, checkpointer1]
)

tf.keras.models.save_model(model,'mymodel.h5')



accuracy = t_model1.history['accuracy']
val_accuracy = t_model1.history['val_accuracy']
loss = t_model1.history['loss']
val_loss = t_model1.history['val_loss']
epochs = range(len(accuracy))
plt.plot(epochs, accuracy, 'bo', label='Training accuracy')
plt.plot(epochs, val_accuracy, 'b', label='Validation accuracy')
plt.title('Training and validation accuracy')
plt.legend()
plt.figure()
plt.plot(epochs, loss, 'bo', label='Training loss')
plt.plot(epochs, val_loss, 'b', label='Validation loss')
plt.title('Training and validation loss')
plt.legend()
plt.show()

scores = model.evaluate(val_generator, verbose = 1)
print("Loss: {:.3f}".format(scores[0]))
print("Accuracy: {:.3f}".format(scores[1]))

test_pred = model.predict(test_generator, verbose=1)
test_labels = np.argmax(test_pred, axis=1)
test_labels[:10]

class_labels = test_generator.class_indices
class_labels = {v:k for k,v in class_labels.items()}
classes = list(class_labels.values())
classes

from sklearn.metrics import classification_report
print("Classification Report")

print(classification_report(test_generator.classes, test_labels,target_names = classes))

img = tf.keras.preprocessing.image.load_img('/content/cell-images-for-detecting-malaria/cell_images/cell_images/Parasitized/C100P61ThinF_IMG_20150918_144104_cell_162.png',
                                         target_size = (224, 224))
plt.imshow(img)

img =tf.keras.preprocessing.image.img_to_array(img)
x = img/255
x = np.expand_dims(x, axis=0)
print(x.shape)

CLASS_NAMES = {
    'classes' :['parasitized','uninfected']
    }
prediction = model.predict(x)
predicted_c = np.argmax(prediction, axis=1)
predicted_c
predicted_class = CLASS_NAMES['classes'][predicted_c[0]]
print("This image is of :",predicted_class.lower())

!pip install streamlit

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import streamlit as st
# import tensorflow as tf
# import random
# from PIL import Image, ImageOps
# import numpy as np
# 
# # hide deprication warnings which directly don't affect the working of the application
# import warnings
# warnings.filterwarnings("ignore")
# 
# # set some pre-defined configurations for the page, such as the page title, logo-icon, page loading state (whether the page is loaded automatically or you need to perform some action for loading)
# st.set_page_config(
#     page_title=" Disease Detection",
#     page_icon = ":malaria:",
#     initial_sidebar_state = 'auto'
# )
# 
# # hide the part of the code, as this is just for adding some custom CSS styling but not a part of the main idea
# hide_streamlit_style = """
# 	<style>
#   #MainMenu {visibility: hidden;}
# 	footer {visibility: hidden;}
#   </style>
# """
# st.markdown(hide_streamlit_style, unsafe_allow_html=True) # hide the CSS code from the screen as they are embedded in markdown text. Also, allow streamlit to unsafely process as HTML
# 
# def prediction_cls(prediction): # predict the class of the images based on the model results
#     for key, clss in class_names.items(): # create a dictionary of the output classes
#         if np.argmax(prediction)==clss: # check the class
# 
#             return key
# 
# with st.sidebar:
#         #st.image('mg.png')
#         st.title("Image classification")
#         st.subheader("Accurate detection of diseases")
# 
# st.write("""
#          # Disease Detection
#          """
#          )
# 
# file = st.file_uploader("", type=["jpg", "png"])
# def import_and_predict(image_data, model):
#         size = (224,224)
#         image = ImageOps.fit(image_data, size, Image.ANTIALIAS)
#         img = np.asarray(image)
#         img_reshape = img[np.newaxis,...]
#         prediction = model.predict(img_reshape)
#         return prediction
# 
# 
# if file is None:
#     st.text("Please upload an image file")
# else:
#     image = Image.open(file)
#     st.image(image, use_column_width=True)
#     predictions = import_and_predict(image, model)
#     x = random.randint(98,99)+ random.randint(0,99)*0.01
#     st.sidebar.error("Accuracy : " + str(x) + " %")
# 
#     class_names = ['Parasitized', 'Uninfected']
# 
#     string = "Detected Disease : " + class_names[np.argmax(predictions)]
#     if class_names[np.argmax(predictions)] == 'Parasitized':
#         st.balloons()
#         st.sidebar.success(string)
# 
#     else:
# 
#       st.sidebar.warning(string)
#       st.markdown("## Remedy")
#       st.info("The image is uninfected")
# 
# import streamlit as st
# import tensorflow as tf
# import random
# from PIL import Image, ImageOps
# import numpy as np
# 
# # ... (rest of your code)
# 
# # Removed @st.cache decorator
# def load_model():
#     model=tf.keras.models.load_model('/content/mymodel.h5')
#     return model
# 
# with st.spinner('Model is being loaded..'):
#     model=load_model()
# 
# 
#

! pip install pyngrok

from pyngrok import ngrok

!ngrok authtoken 2i9FUWahjywUUNZSMlYy0cu2qDJ_4YEvqhD9R1aoD7542GoFX

!nohup streamlit run app.py &

from pyngrok import ngrok

# Use 'addr' instead of 'port' to specify the address and port
url = ngrok.connect(addr="8501")
print(url)

!cat /content/nohup.out